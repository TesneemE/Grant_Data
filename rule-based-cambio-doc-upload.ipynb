{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12536605,"sourceType":"datasetVersion","datasetId":7914470}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport json\nimport re\nfrom datetime import datetime\nfrom pathlib import Path\nfrom shutil import copyfile\nfrom urllib.parse import quote_plus\n\nimport nltk\nfrom pydrive2.auth import GoogleAuth\nfrom pydrive2.drive import GoogleDrive\nfrom kaggle_secrets import UserSecretsClient\n!pip install --quiet langchain langchain-community unstructured[docx]\n\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import pipeline\n# from langchain_unstructured import UnstructuredLoader as UnstructuredFileLoader\nfrom langchain_community.document_loaders import UnstructuredFileLoader\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T17:16:38.831118Z","iopub.execute_input":"2025-07-22T17:16:38.831428Z","iopub.status.idle":"2025-07-22T17:17:39.737551Z","shell.execute_reply.started":"2025-07-22T17:16:38.831403Z","shell.execute_reply":"2025-07-22T17:17:39.736321Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.6/212.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 24.1.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2025-07-22 17:17:16.907394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753204637.145032      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753204637.213276      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# === NLTK Setup ===\nrequired_nltk_packages = [\n    \"punkt\", \"averaged_perceptron_tagger\", \"maxent_ne_chunker\", \"words\", \"stopwords\"\n]\n\ndef nltk_package_path(package):\n    return {\n        \"punkt\": \"tokenizers/punkt\",\n        \"averaged_perceptron_tagger\": \"taggers/averaged_perceptron_tagger\",\n        \"maxent_ne_chunker\": \"chunkers/maxent_ne_chunker\",\n        \"words\": \"corpora/words\",\n        \"stopwords\": \"corpora/stopwords\"\n    }.get(package, package)\n\nfor package in required_nltk_packages:\n    try:\n        nltk.data.find(f\"{nltk_package_path(package)}\")\n    except LookupError:\n        nltk.download(package)\n\n# === Models ===\nembedding_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")\nllm = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=0, max_new_tokens=512)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T17:17:39.739305Z","iopub.execute_input":"2025-07-22T17:17:39.740019Z","iopub.status.idle":"2025-07-22T17:18:08.002496Z","shell.execute_reply.started":"2025-07-22T17:17:39.739991Z","shell.execute_reply":"2025-07-22T17:18:08.001002Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e4426c310af44b9ae7e33517a8a7c08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce45c00b99442ec905a10fff2b67683"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b6234dd2e26462ab171235e3900a7e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0e9b963e8db4acc9d9d65a6ed2c730d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8abe16ef4fa143139d771aea7d266a1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33dd7109d98e43b29dd0df04a3a31a9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"869f150ef4bf41258c53189c4134313b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0e29b72fc034f1ca4b70400ade27284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fa1edf0f8ea4612b35f04ef250db669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6642f5ec26574ae4a66623f35a27068d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea867e521b7488f949190ddab7b85eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14210220ca03490ebcc0cbf23b5641c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b726f1e7a97464291ef495f4a236841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"751a94295a234ea999f85a9829d6483f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b56e209ee0c74da78fbf3eabf7854986"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37a0859b607c4fcb9fdf1dc33282e093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b5d5aa6f5ba420bbeb1516f76d1af00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b1af7dc62264b13a88d5af0f4cdc6de"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# === Config ===\n# WATCH_FOLDER_ID = \"17sSWn0cfX-jEFmgG4Hl-P9_NtG9kqS6D\"\nWATCH_FOLDER_ID=\"1tJhw1KbempeSjoHfkJ-Ig6Ikn-bKL20Q\" #test folder\nDOWNLOAD_PATH = Path(\"/tmp/gdrive_docs\")\nDOWNLOAD_PATH.mkdir(parents=True, exist_ok=True)\n\n# === Auth ===\nCRED_INPUT = \"/kaggle/input/google-cred/credentials.json\"\nCRED_WORKING = \"/kaggle/working/credentials.json\"\ncopyfile(CRED_INPUT, CRED_WORKING)\n\ngauth = GoogleAuth()\ngauth.LoadCredentialsFile(CRED_WORKING)\nif gauth.credentials is None:\n    gauth.LocalWebserverAuth()\nelif gauth.access_token_expired:\n    gauth.Refresh()\nelse:\n    gauth.Authorize()\ngauth.SaveCredentialsFile(CRED_WORKING)\ndrive = GoogleDrive(gauth)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T17:18:08.003764Z","iopub.execute_input":"2025-07-22T17:18:08.004133Z","iopub.status.idle":"2025-07-22T17:18:08.142693Z","shell.execute_reply.started":"2025-07-22T17:18:08.004102Z","shell.execute_reply":"2025-07-22T17:18:08.141593Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# === HELPERS ===\ndef sanitize_filename(title):\n    return re.sub(r'[\\\\/*?:\"<>|]', \"_\", title)\n\ndef detect_format_style(text):\n    bold_qs = len(re.findall(r\"\\n[A-Z][^\\n]{4,100}\\?\\s*\\n\", text))\n    return \"bolded_qs\" if bold_qs > 3 else \"narrative\"\n\ndef llm_extract_qa_pairs(text):\n    prompt = (\n        \"\"\"Extract question and answer pairs from the grant text below. Use format:\nQ: [Question]\nA: [Answer]\n\nText:\n\"\"\"\n        f\"{text}\"\n    )\n    try:\n        output = llm(prompt.strip())[0][\"generated_text\"]\n        pairs = re.findall(r\"Q:\\s*(.+?)\\s*A:\\s*(.+?)(?=\\nQ:|\\Z)\", output, re.DOTALL)\n        return [{\"question\": q.strip(), \"answer\": a.strip()} for q, a in pairs]\n    except Exception as e:\n        print(f\"⚠️ LLM Q&A extraction failed: {e}\")\n        return []\n\ndef extract_qa_pairs(text):\n    q_pattern = re.compile(r\"(?=(?:^|\\n)([^:\\n]{4,100}[\\?:])\\s*\\n?)\", re.MULTILINE)\n    splits = q_pattern.split(text)\n    qa_pairs = []\n    for i in range(1, len(splits), 2):\n        question = splits[i].strip()\n        answer = splits[i+1].strip() if i+1 < len(splits) else \"\"\n        if len(answer) > 10 and len(question) > 5:\n            qa_pairs.append({\"question\": question, \"answer\": answer})\n    return qa_pairs\n\ndef categorize_chunk(text: str, question: str = \"\") -> list:\n    categories = []\n    lower_text = text.lower()\n    lower_q = question.lower()\n    if \"problem\" in lower_q or \"we address\" in lower_text:\n        categories.append(\"Contact Information Problem\")\n    if \"mission\" in lower_q or \"mission\" in lower_text:\n        categories.append(\"Mission Statement\")\n    if len(text) < 400:\n        categories.append(\"Project Summary\")\n    if \"goal\" in lower_q or \"vision\" in lower_q:\n        categories.append(\"Goals, Vision, or Objectives\")\n    if \"approach\" in lower_q or \"methodology\" in lower_text:\n        categories.append(\"Our Solution or Approach\")\n    if \"impact\" in lower_q or \"results\" in lower_q:\n        categories.append(\"Impact Results or Outcomes\")\n    if \"who benefits\" in lower_q or \"target population\" in lower_q:\n        categories.append(\"Beneficiaries\")\n    if \"unique\" in lower_text:\n        categories.append(\"Unique Value Proposition\")\n    if \"timeline\" in lower_q:\n        categories.append(\"Plan and Timeline\")\n    if \"budget\" in lower_q or \"$\" in text:\n        categories.append(\"Budget and Funding\")\n    if \"sustainability\" in lower_text:\n        categories.append(\"Sustainability or Strategy\")\n    if \"team\" in lower_q or \"lived experience\" in lower_text:\n        categories.append(\"Team Members and Descriptions\")\n    if re.search(r\"\\\\bfounded\\\\b|\\\\bhistory\\\\b|\\\\baccelerator\\\\b\", lower_text):\n        categories.append(\"Organizational History\")\n    if re.search(r\"(https?://\\\\S+)\", lower_text):\n        categories.append(\"Supplementary Materials\")\n    if not categories:\n        categories.append(\"Miscellaneous\")\n    return categories\n\ndef annotate_chunk(chunk_text: str) -> dict:\n    prompt = (\n        \"\"\"You are a grant document assistant.\nAnalyze the following text and return the most likely category it fits into.\nPossible categories include: Mission Statement, Problem, Team, Impact, Sustainability, etc.\nReturn only JSON in the format:\n{\"question\": \"...\", \"answer\": \"...\", \"category\": \"...\"}\n\nTEXT:\n\"\"\"\n        f\"{chunk_text}\"\n    )\n    try:\n        result = llm(prompt.strip())[0]['generated_text']\n        match = re.search(r\"\\{.*\\}\", result, re.DOTALL)\n        if match:\n            return json.loads(match.group())\n        else:\n            raise ValueError(\"No JSON found in model output\")\n    except Exception as e:\n        print(f\"⚠️ LLM error: {e}\")\n        return {\"question\": None, \"answer\": None, \"category\": \"Miscellaneous\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T17:18:08.145330Z","iopub.execute_input":"2025-07-22T17:18:08.145677Z","iopub.status.idle":"2025-07-22T17:18:10.428585Z","shell.execute_reply.started":"2025-07-22T17:18:08.145654Z","shell.execute_reply":"2025-07-22T17:18:10.427335Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# === FILE CHECKER ===\ndef check_for_new_files():\n    print(f\"\\U0001F50D Checking for new files at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    file_list = drive.ListFile({'q': f\"'{WATCH_FOLDER_ID}' in parents and trashed=false\"}).GetList()\n\n    for file in file_list:\n        title = file['title']\n        file_id = file['id']\n        modified_time = file['modifiedDate']\n        sanitized_title = sanitize_filename(title)\n        file_path = DOWNLOAD_PATH / f\"{sanitized_title}.docx\"\n\n        # existing = structured_col.find_one({\"metadata.title\": title})\n        # if existing and existing.get(\"metadata\", {}).get(\"modifiedDate\") == modified_time:\n        #     print(f\"✅ Already processed: {title}\")\n        #     continue\n\n        print(f\"⬇ Downloading: {title}\")\n        file.GetContentFile(str(file_path), mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document')\n\n        loader = UnstructuredFileLoader(str(file_path))\n        pages = loader.load()\n        raw_text = pages[0].page_content\n        doc_id = title.replace(\" \", \"_\").lower()\n\n        qa_pairs = extract_qa_pairs(raw_text)\n\n        doc_entry = {\n            \"doc_id\": doc_id,\n            \"metadata\": {\n                \"title\": title,\n                \"doc_id\": doc_id,\n                \"file_id\": file_id,\n                \"modifiedDate\": modified_time,\n                \"word_count\": len(raw_text.split()),\n            },\n            \"chunks\": []\n        }\n\n        flat_chunks = []\n\n        for i, pair in enumerate(qa_pairs):\n            q, a = pair['question'], pair['answer']\n            categories = categorize_chunk(a, q)\n            if categories == [\"Miscellaneous\"]:\n                annotations = annotate_chunk(a)\n                categories = [annotations[\"category\"]] if annotations[\"category\"] else [\"Miscellaneous\"]\n            for cat in categories:\n                chunk_id = f\"{doc_id}_chunk_{i}_{cat.replace(' ', '_')}\"\n                try:\n                    embedding = embedding_model.encode(a).tolist()\n                except Exception as e:\n                    print(f\"⚠️ Embedding error: {e}\")\n                    embedding = None\n\n                chunk_data = {\n                    \"chunk_id\": chunk_id,\n                    \"text\": a,\n                    \"embedding\": embedding,\n                    \"question\": q,\n                    \"answer\": a,\n                    \"word_count\": len(a.split()),\n                    \"metadata\": {\n                        \"doc_id\": doc_id,\n                        \"title\": title,\n                        \"file_id\": file_id,\n                        \"modifiedDate\": modified_time,\n                        \"category\": cat\n                    }\n                }\n                doc_entry[\"chunks\"].append(chunk_data)\n                flat_chunks.append(chunk_data)\n\n        # structured_col.delete_many({\"metadata.title\": title})\n        # flat_col.delete_many({\"metadata.doc_id\": doc_id})\n\n        # structured_col.insert_one(doc_entry)\n        # if flat_chunks:\n        #     flat_col.insert_many(flat_chunks)\n        with open(f\"/kaggle/working/{doc_id}_structured.json\", \"w\") as f:\n            json.dump(doc_entry, f, indent=2)\n        with open(f\"/kaggle/working/{doc_id}_flat.json\", \"w\") as f:\n            json.dump(flat_chunks, f, indent=2)\n\n\n        print(f\"✅ Processed and inserted: {title}\")\n\n        try:\n            os.remove(file_path)\n        except Exception as e:\n            print(f\"⚠️ Failed to delete file: {e}\")\n\n    print(\"✅ Check complete.\\n\")\n\nif __name__ == \"__main__\":\n    check_for_new_files()\n# === LOOP ===\n# while True:\n#     check_for_new_files()\n#     print(\"⏲️ Sleeping for 5 minutes...\\n\")\n#     time.sleep(300)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T17:18:10.430314Z","iopub.execute_input":"2025-07-22T17:18:10.430627Z","iopub.status.idle":"2025-07-22T17:18:48.494361Z","shell.execute_reply.started":"2025-07-22T17:18:10.430599Z","shell.execute_reply":"2025-07-22T17:18:48.493103Z"}},"outputs":[{"name":"stdout","text":"🔍 Checking for new files at 2025-07-22 17:18:11\n⬇ Downloading: Copy of DATA - Queens Tech Challenge\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/444122703.py:21: LangChainDeprecationWarning: The class `UnstructuredFileLoader` was deprecated in LangChain 0.2.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-unstructured package and should be used instead. To use it run `pip install -U :class:`~langchain-unstructured` and import as `from :class:`~langchain_unstructured import UnstructuredLoader``.\n  loader = UnstructuredFileLoader(str(file_path))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfab72309f8d4da298fdb209be714c7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26ac0eb0882e42cd9aec51892b4b19e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f131042b58c4addbccfbc08ae7814b4"}},"metadata":{}},{"name":"stdout","text":"⚠️ LLM error: No JSON found in model output\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c90240ff46664d5da96d48f410204e50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b891ec60fc18404096a081bada85234c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60cdd685d30841f8bbb3b76a0c7cc2c6"}},"metadata":{}},{"name":"stdout","text":"⚠️ LLM error: No JSON found in model output\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e48a105cc7447c89ab53635786b83b7"}},"metadata":{}},{"name":"stdout","text":"⚠️ LLM error: No JSON found in model output\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79e155aefc3f47aa879bca5b972bfc61"}},"metadata":{}},{"name":"stdout","text":"⚠️ LLM error: No JSON found in model output\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90eefaf8c39144e3912f79e55b4edaeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a987a435e17741ecbb8fb4e70aaa2e32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5c9f77b23494cc6bea2772c969ae23b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888104f6a5bd445ebf811c9e56c413c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8241fc1af9e7414c8374971923d362fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"077b35384f314183adcd164b12f8eb48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d143c85e7e547a28eac9b718c868a04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6072bf532944a8a6bdb5a11a544987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8234231159940469746fcd42585225d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a4f4c97bcaa4542b0d321d8e652f3be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6909656b02b645f2b60a5f7c87edaad2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94daa21ad1864f6f93b6911931eb4836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"045717b1aac443de9599a311cbe7a8a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb67ca66de6d499d9e4e3df50f89b37a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"946e849b680747c5b6b7e104d40fd7a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c55af7cb9b3e436a88e46808ab83122e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5f2bbf7bb2d414abfc9c76fd0985e30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6852acea615475693562fb8b6556deb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1e4c945c1954319a2a15d34a3333328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ab920415fd44719968f74c5e75b80f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57118101dc244e6ead7ccd873ebe9e88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7543a29dc894a29b1d1471a4976de6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2c042eb61b543c69cb1dc7e4152ce5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf80cf9137047f691fd1fdd2e9cc809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e17aaec8e7b54e3ea0780320274302fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90924f36194d43c88159d5d9a3d2b07a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3154957aec444c8a72f43e91290febd"}},"metadata":{}},{"name":"stdout","text":"✅ Processed and inserted: Copy of DATA - Queens Tech Challenge\n⬇ Downloading: Copy of DATA - Application YASS\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305be1a9c32c49a0b6219d36af3a9a84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c61b8ae6e7a647e4a0a8b9df400f61bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f2e1ad4960a4067a09e2d462970b6da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ebb537bdf354a9292ff975af9b63c52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b118382f1bbb407cb2a8140ff1cc1475"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a302760b80f470a9271d029d7031285"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f1f20e1ac704144a19353f2ddda3a7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5f1d9e6cc3943d29b7bd2b880cbd91b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5c649d0051a4bf09f13a443b409c57b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eb1f650cba3408abfa63b241b7206ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b331cf900bec43eda16ab58a3a365e77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68f5cc2e21641968a8801646429f81e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb1dd29021da498dba1224020347174e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda1395826754235821493f66e612dbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f921e118b824ef594830a0c056162ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a976a111fcf473c8d8df6ce8ae6a799"}},"metadata":{}},{"name":"stdout","text":"⚠️ LLM error: No JSON found in model output\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b29495d8024454a89da0965b84e3690"}},"metadata":{}},{"name":"stdout","text":"⚠️ LLM error: No JSON found in model output\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98c397aefe1c4e938007cb714f772914"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a881959c3b2e48d098a0875907b44e75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fccb47ba976a4018a9e15cd93bf1b1b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9685f35ac1cd4a80bfe14ca9f5010f65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ad7b45c6a64e3b81e77b0232ac659c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f138e48318341bd86ab919e71950f43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be3298a6ce094aaeb7e732e211f1f2d5"}},"metadata":{}},{"name":"stdout","text":"✅ Processed and inserted: Copy of DATA - Application YASS\n✅ Check complete.\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# # === Main ===\n# def check_for_new_files():\n#     print(f\"🔍 Checking for new files at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n#     file_list = drive.ListFile({'q': f\"'{WATCH_FOLDER_ID}' in parents and trashed=false\"}).GetList()\n\n#     for file in file_list:\n#         title = file['title']\n#         file_id = file['id']\n#         modified_time = file['modifiedDate']\n\n#         # Make filename safe\n#         doc_id = sanitize_filename(title.replace(\" \", \"_\").lower())\n\n#         # Skip if structured JSON already exists\n#         if Path(f\"/kaggle/working/{doc_id}_structured.json\").exists():\n#             print(f\"✅ Already processed locally: {title}\")\n#             continue\n\n#         print(f\"⬇ Downloading: {title}\")\n#         file_path = DOWNLOAD_PATH / f\"{sanitize_filename(title)}.docx\"\n#         file.GetContentFile(str(file_path), mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document')\n\n#         loader = UnstructuredFileLoader(str(file_path))\n#         pages = loader.load()\n#         raw_text = pages[0].page_content\n#         word_count = len(raw_text.split())\n\n#         flat_chunks = []\n\n#         for i, page in enumerate(pages):\n#             chunks = chunk_text(page.page_content)\n#             for j, chunk in enumerate(chunks):\n#                 qa = generate_qa_pair(chunk)\n#                 try:\n#                     embedding = embedding_model.encode(chunk).tolist()\n#                 except Exception as e:\n#                     print(f\"⚠️ Embedding error: {e}\")\n#                     embedding = None\n\n#                 chunk_data = {\n#                     \"chunk_id\": f\"{doc_id}_chunk_{i}_{j}\",\n#                     \"text\": chunk,\n#                     \"embedding\": embedding,\n#                     \"question\": qa[\"question\"],\n#                     \"answer\": qa[\"answer\"],\n#                     \"word_count\": len(chunk.split()),\n#                     \"metadata\": {\n#                         \"doc_id\": doc_id,\n#                         \"title\": title,\n#                         \"file_id\": file_id,\n#                         \"modifiedDate\": modified_time,\n#                         \"category\": qa[\"category\"]\n#                     }\n#                 }\n#                 flat_chunks.append(chunk_data)\n\n#         doc_entry = {\n#             \"doc_id\": doc_id,\n#             \"metadata\": {\n#                 \"title\": title,\n#                 \"doc_id\": doc_id,\n#                 \"file_id\": file_id,\n#                 \"modifiedDate\": modified_time,\n#                 \"word_count\": word_count\n#             },\n#             \"chunks\": flat_chunks\n#         }\n\n#         # Save flat and structured JSONs in /kaggle/working\n#         with open(f\"/kaggle/working/{doc_id}_structured.json\", \"w\") as f:\n#             json.dump(doc_entry, f, indent=2)\n#         with open(f\"/kaggle/working/{doc_id}_flat.json\", \"w\") as f:\n#             json.dump(flat_chunks, f, indent=2)\n\n#         try:\n#             os.remove(file_path)\n#         except Exception as e:\n#             print(f\"⚠️ Failed to delete file: {e}\")\n\n#     print(\"✅ Check complete.\\n\")\n\n# if __name__ == \"__main__\":\n#     check_for_new_files()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T17:18:48.496452Z","iopub.execute_input":"2025-07-22T17:18:48.496852Z","iopub.status.idle":"2025-07-22T17:18:48.503519Z","shell.execute_reply.started":"2025-07-22T17:18:48.496816Z","shell.execute_reply":"2025-07-22T17:18:48.502374Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport shutil\nfrom pathlib import Path\nimport zipfile\n\nWORKING_DIR = Path(\"/kaggle/working\")\nSTRUCTURED_DIR = WORKING_DIR / \"structured\"\nFLAT_DIR = WORKING_DIR / \"flat\"\n\n# Create folders if they don't exist\nSTRUCTURED_DIR.mkdir(exist_ok=True)\nFLAT_DIR.mkdir(exist_ok=True)\n\n# Move JSON files into their respective folders\nfor file in WORKING_DIR.glob(\"*.json\"):\n    if file.name.endswith(\"_structured.json\"):\n        shutil.move(str(file), STRUCTURED_DIR / file.name)\n    elif file.name.endswith(\"_flat.json\"):\n        shutil.move(str(file), FLAT_DIR / file.name)\n\n# Function to zip a folder\ndef zip_folder(folder_path: Path, zip_path: Path):\n    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for file in folder_path.rglob('*'):\n            zipf.write(file, arcname=file.relative_to(folder_path))\n\n# Zip both folders\nzip_folder(STRUCTURED_DIR, WORKING_DIR / \"structured.zip\")\nzip_folder(FLAT_DIR, WORKING_DIR / \"flat.zip\")\n\nprint(\"✅ Folders zipped to:\")\nprint(\" - structured.zip\")\nprint(\" - flat.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T17:18:48.504847Z","iopub.execute_input":"2025-07-22T17:18:48.505214Z","iopub.status.idle":"2025-07-22T17:18:48.605782Z","shell.execute_reply.started":"2025-07-22T17:18:48.505180Z","shell.execute_reply":"2025-07-22T17:18:48.604501Z"}},"outputs":[{"name":"stdout","text":"✅ Folders zipped to:\n - structured.zip\n - flat.zip\n","output_type":"stream"}],"execution_count":7}]}